{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ori Text</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Input IDs</th>\n",
       "      <th>Label</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>CleanedSummary</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>BERT_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>['good', 'quality', 'dog', 'food']</td>\n",
       "      <td>[2204, 3737, 3899, 2833]</td>\n",
       "      <td>2</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>5</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 1.86347023e-01 -1.68072730e-01 -2.28051543e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>['not', 'as', 'advertised']</td>\n",
       "      <td>[2025, 2004, 17099]</td>\n",
       "      <td>0</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>1</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 1.42439336e-01 -2.03745186e-01  2.30189532e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"delight\" says it all</td>\n",
       "      <td>['\"', 'delight', '\"', 'says', 'it', 'all']</td>\n",
       "      <td>[1000, 12208, 1000, 2758, 2009, 2035]</td>\n",
       "      <td>2</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>\"delight\" says it all</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 1.55589268e-01 -1.47779912e-01  5.19596696e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>['cough', 'medicine']</td>\n",
       "      <td>[19340, 4200]</td>\n",
       "      <td>0</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>2</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 2.84347177e-01  1.18847996e-01 -3.19756150e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>['great', 'ta', '##ffy']</td>\n",
       "      <td>[2307, 11937, 16329]</td>\n",
       "      <td>2</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>5</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 7.87579119e-02  4.56854627e-02  4.53394055e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393555</th>\n",
       "      <td>393555</td>\n",
       "      <td>will not do without</td>\n",
       "      <td>['will', 'not', 'do', 'without']</td>\n",
       "      <td>[2097, 2025, 2079, 2302]</td>\n",
       "      <td>2</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>5</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>will not do without</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 1.87258333e-01  1.27170295e-01  4.31861162e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393556</th>\n",
       "      <td>393556</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>['disappointed']</td>\n",
       "      <td>[9364]</td>\n",
       "      <td>0</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>2</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>0</td>\n",
       "      <td>[-9.47165340e-02  2.12972835e-01  3.75459075e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393557</th>\n",
       "      <td>393557</td>\n",
       "      <td>perfect for our maltipoo</td>\n",
       "      <td>['perfect', 'for', 'our', 'mal', '##tip', '##oo']</td>\n",
       "      <td>[3819, 2005, 2256, 15451, 25101, 9541]</td>\n",
       "      <td>2</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>5</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>perfect for our maltipoo</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 3.62180173e-02 -1.98110163e-01  3.83110881e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393558</th>\n",
       "      <td>393558</td>\n",
       "      <td>favorite training and reward treat</td>\n",
       "      <td>['favorite', 'training', 'and', 'reward', 'tre...</td>\n",
       "      <td>[5440, 2731, 1998, 10377, 7438]</td>\n",
       "      <td>2</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>5</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>favorite training and reward treat</td>\n",
       "      <td>2</td>\n",
       "      <td>[-6.12895228e-02 -4.24842209e-01  2.22797886e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393559</th>\n",
       "      <td>393559</td>\n",
       "      <td>great honey</td>\n",
       "      <td>['great', 'honey']</td>\n",
       "      <td>[2307, 6861]</td>\n",
       "      <td>2</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>5</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>great honey</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 9.20580924e-02  7.12642670e-02  4.33833867e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393560 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                            Ori Text  \\\n",
       "0                0               good quality dog food   \n",
       "1                1                   not as advertised   \n",
       "2                2               \"delight\" says it all   \n",
       "3                3                      cough medicine   \n",
       "4                4                         great taffy   \n",
       "...            ...                                 ...   \n",
       "393555      393555                 will not do without   \n",
       "393556      393556                        disappointed   \n",
       "393557      393557            perfect for our maltipoo   \n",
       "393558      393558  favorite training and reward treat   \n",
       "393559      393559                         great honey   \n",
       "\n",
       "                                                   Tokens  \\\n",
       "0                      ['good', 'quality', 'dog', 'food']   \n",
       "1                             ['not', 'as', 'advertised']   \n",
       "2              ['\"', 'delight', '\"', 'says', 'it', 'all']   \n",
       "3                                   ['cough', 'medicine']   \n",
       "4                                ['great', 'ta', '##ffy']   \n",
       "...                                                   ...   \n",
       "393555                   ['will', 'not', 'do', 'without']   \n",
       "393556                                   ['disappointed']   \n",
       "393557  ['perfect', 'for', 'our', 'mal', '##tip', '##oo']   \n",
       "393558  ['favorite', 'training', 'and', 'reward', 'tre...   \n",
       "393559                                 ['great', 'honey']   \n",
       "\n",
       "                                     Input IDs  Label   ProductId  \\\n",
       "0                     [2204, 3737, 3899, 2833]      2  B001E4KFG0   \n",
       "1                          [2025, 2004, 17099]      0  B00813GRG4   \n",
       "2        [1000, 12208, 1000, 2758, 2009, 2035]      2  B000LQOCH0   \n",
       "3                                [19340, 4200]      0  B000UA0QIQ   \n",
       "4                         [2307, 11937, 16329]      2  B006K2ZZ7K   \n",
       "...                                        ...    ...         ...   \n",
       "393555                [2097, 2025, 2079, 2302]      2  B001EO7N10   \n",
       "393556                                  [9364]      0  B003S1WTCU   \n",
       "393557  [3819, 2005, 2256, 15451, 25101, 9541]      2  B004I613EE   \n",
       "393558         [5440, 2731, 1998, 10377, 7438]      2  B004I613EE   \n",
       "393559                            [2307, 6861]      2  B001LR2CU2   \n",
       "\n",
       "                UserId  Score                             Summary  \\\n",
       "0       A3SGXH7AUHU8GW      5               Good Quality Dog Food   \n",
       "1       A1D87F6ZCVE5NK      1                   Not as Advertised   \n",
       "2        ABXLMWJIXXAIN      4               \"Delight\" says it all   \n",
       "3       A395BORC6FGVXV      2                      Cough Medicine   \n",
       "4       A1UQRSCLF8GW1T      5                         Great taffy   \n",
       "...                ...    ...                                 ...   \n",
       "393555  A28KG5XORO54AY      5                 Will not do without   \n",
       "393556  A3I8AFVPEE8KI5      2                        disappointed   \n",
       "393557  A121AA1GQV751Z      5            Perfect for our maltipoo   \n",
       "393558   A3IBEVCTXKNOH      5  Favorite Training and reward treat   \n",
       "393559  A3LGQPJCZVL9UC      5                         Great Honey   \n",
       "\n",
       "                            CleanedSummary  Sentiment  \\\n",
       "0                    good quality dog food          2   \n",
       "1                        not as advertised          0   \n",
       "2                    \"delight\" says it all          2   \n",
       "3                           cough medicine          0   \n",
       "4                              great taffy          2   \n",
       "...                                    ...        ...   \n",
       "393555                 will not do without          2   \n",
       "393556                        disappointed          0   \n",
       "393557            perfect for our maltipoo          2   \n",
       "393558  favorite training and reward treat          2   \n",
       "393559                         great honey          2   \n",
       "\n",
       "                                                BERT_Text  \n",
       "0       [ 1.86347023e-01 -1.68072730e-01 -2.28051543e-...  \n",
       "1       [ 1.42439336e-01 -2.03745186e-01  2.30189532e-...  \n",
       "2       [ 1.55589268e-01 -1.47779912e-01  5.19596696e-...  \n",
       "3       [ 2.84347177e-01  1.18847996e-01 -3.19756150e-...  \n",
       "4       [ 7.87579119e-02  4.56854627e-02  4.53394055e-...  \n",
       "...                                                   ...  \n",
       "393555  [ 1.87258333e-01  1.27170295e-01  4.31861162e-...  \n",
       "393556  [-9.47165340e-02  2.12972835e-01  3.75459075e-...  \n",
       "393557  [ 3.62180173e-02 -1.98110163e-01  3.83110881e-...  \n",
       "393558  [-6.12895228e-02 -4.24842209e-01  2.22797886e-...  \n",
       "393559  [ 9.20580924e-02  7.12642670e-02  4.33833867e-...  \n",
       "\n",
       "[393560 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cleaned_merged.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [0.18634702, -0.16807273, -0.22805154, 0.20733...\n",
      "1    [0.14243934, -0.20374519, 0.23018953, 0.121963...\n",
      "2    [0.15558927, -0.14777991, 0.5195967, 0.2591147...\n",
      "3    [0.28434718, 0.118847996, -0.31975615, 0.02868...\n",
      "4    [0.07875791, 0.045685463, 0.45339406, 0.010217...\n",
      "Name: BERT_Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to clean and parse the BERT output\n",
    "def parse_bert_output(text):\n",
    "    # Replace newlines with spaces and strip extra spaces\n",
    "    cleaned_text = text.replace('\\n', ' ').strip()\n",
    "    # Convert space-separated values into a list of floats\n",
    "    numbers = list(map(float, cleaned_text.strip(\"[]\").split()))\n",
    "    return np.array(numbers, dtype=np.float32)\n",
    "\n",
    "# Apply the function to each row of the 'Summary_BERT_Embeddings' column\n",
    "df['BERT_Text'] = df['BERT_Text'].apply(parse_bert_output)\n",
    "\n",
    "# Verify by printing the first few rows of the cleaned embeddings\n",
    "print(df['BERT_Text'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert BERT_Text (assumed to be a list of embeddings) into a NumPy array\n",
    "X = np.vstack(df['BERT_Text'].values)\n",
    "y = df['Label'].values  # Target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920238, 768)\n",
      "(920238,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "print(X_resampled.shape)\n",
    "print(y_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Distribution:\n",
      "2    306746\n",
      "0    306746\n",
      "1    306746\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sentiment_counts = pd.Series(y_resampled).value_counts()\n",
    "\n",
    "print(\"Sentiment Distribution:\")\n",
    "print(sentiment_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736190, 768)\n",
      "(184048, 768)\n",
      "(736190,)\n",
      "(184048,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train_80, X_test_20, y_train_80, y_test_20 = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
    "\n",
    "print(X_train_80.shape)\n",
    "print(X_test_20.shape)\n",
    "print(y_train_80.shape)\n",
    "print(y_test_20.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[32m      3\u001b[39m lr_model = LogisticRegression(max_iter=\u001b[32m1000\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mlr_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_80\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_80\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1350\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1348\u001b[39m     n_threads = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1350\u001b[39m fold_coefs_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1364\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m fold_coefs_, _, n_iter_ = \u001b[38;5;28mzip\u001b[39m(*fold_coefs_)\n\u001b[32m   1376\u001b[39m \u001b[38;5;28mself\u001b[39m.n_iter_ = np.asarray(n_iter_, dtype=np.int32)[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:451\u001b[39m, in \u001b[36m_logistic_regression_path\u001b[39m\u001b[34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[39m\n\u001b[32m    447\u001b[39m l2_reg_strength = \u001b[32m1.0\u001b[39m / (C * sw_sum)\n\u001b[32m    448\u001b[39m iprint = [-\u001b[32m1\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m101\u001b[39m][\n\u001b[32m    449\u001b[39m     np.searchsorted(np.array([\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m]), verbose)\n\u001b[32m    450\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m opt_res = \u001b[43moptimize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxiter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43miprint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgtol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mftol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m n_iter_i = _check_optimize_result(\n\u001b[32m    466\u001b[39m     solver,\n\u001b[32m    467\u001b[39m     opt_res,\n\u001b[32m    468\u001b[39m     max_iter,\n\u001b[32m    469\u001b[39m     extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[32m    470\u001b[39m )\n\u001b[32m    471\u001b[39m w0, loss = opt_res.x, opt_res.fun\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:738\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    735\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    736\u001b[39m                              **options)\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m738\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    741\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    742\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:441\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[39m\n\u001b[32m    433\u001b[39m _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    434\u001b[39m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    437\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    438\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    439\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    440\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    443\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    444\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:344\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.array_equal(x, \u001b[38;5;28mself\u001b[39m.x):\n\u001b[32m    343\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x(x)\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[38;5;28mself\u001b[39m._update_grad()\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:295\u001b[39m, in \u001b[36mScalarFunction._update_fun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f_updated:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m         fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m fx < \u001b[38;5;28mself\u001b[39m._lowest_f:\n\u001b[32m    297\u001b[39m             \u001b[38;5;28mself\u001b[39m._lowest_x = \u001b[38;5;28mself\u001b[39m.x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:21\u001b[39m, in \u001b[36m_wrapper_fun.<locals>.wrapped\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     17\u001b[39m ncalls[\u001b[32m0\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m fx = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isscalar(fx):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:80\u001b[39m, in \u001b[36mMemoizeJac.__call__\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args):\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:74\u001b[39m, in \u001b[36mMemoizeJac._compute_if_needed\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(x == \u001b[38;5;28mself\u001b[39m.x) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.x = np.asarray(x).copy()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     fg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.jac = fg[\u001b[32m1\u001b[39m]\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m._value = fg[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:316\u001b[39m, in \u001b[36mLinearModelLoss.loss_gradient\u001b[39m\u001b[34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    314\u001b[39m     weights, intercept = \u001b[38;5;28mself\u001b[39m.weight_intercept(coef)\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m loss, grad_pointwise = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m sw_sum = n_samples \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np.sum(sample_weight)\n\u001b[32m    323\u001b[39m loss = loss.sum() / sw_sum\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mochi\\OneDrive\\Documents\\MMU\\Bachelors in Computer Science\\FYP\\code\\code\\.venv\\Lib\\site-packages\\sklearn\\_loss\\loss.py:205\u001b[39m, in \u001b[36mBaseLoss.loss_gradient\u001b[39m\u001b[34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28mself\u001b[39m.closs.loss(\n\u001b[32m    197\u001b[39m         y_true=y_true,\n\u001b[32m    198\u001b[39m         raw_prediction=raw_prediction,\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m         n_threads=n_threads,\n\u001b[32m    202\u001b[39m     )\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_out\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloss_gradient\u001b[39m(\n\u001b[32m    206\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    207\u001b[39m     y_true,\n\u001b[32m    208\u001b[39m     raw_prediction,\n\u001b[32m    209\u001b[39m     sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    210\u001b[39m     loss_out=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    211\u001b[39m     gradient_out=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    212\u001b[39m     n_threads=\u001b[32m1\u001b[39m,\n\u001b[32m    213\u001b[39m ):\n\u001b[32m    214\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute loss and gradient w.r.t. raw_prediction for each input.\u001b[39;00m\n\u001b[32m    215\u001b[39m \n\u001b[32m    216\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m \u001b[33;03m        Element-wise gradients.\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m loss_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_80, y_train_80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6989481004955229\n",
      "Precision: 0.6972339077122365\n",
      "Recall: 0.6989481004955229\n",
      "F1-Score: 0.6976021127961409\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70     61349\n",
      "           1       0.64      0.59      0.61     61349\n",
      "           2       0.77      0.78      0.78     61350\n",
      "\n",
      "    accuracy                           0.70    184048\n",
      "   macro avg       0.70      0.70      0.70    184048\n",
      "weighted avg       0.70      0.70      0.70    184048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test_20)\n",
    "\n",
    "accuracy = accuracy_score(y_test_20, y_pred_lr)\n",
    "precision = precision_score(y_test_20, y_pred_lr, average='weighted')\n",
    "recall = recall_score(y_test_20, y_pred_lr, average='weighted')\n",
    "f1 = f1_score(y_test_20, y_pred_lr, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:}\")\n",
    "print(f\"Precision: {precision:}\")\n",
    "print(f\"Recall: {recall:}\")\n",
    "print(f\"F1-Score: {f1:}\")\n",
    "\n",
    "# Print a classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_20, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7127108145701121\n",
      "Precision: 0.7125643836495418\n",
      "Recall: 0.7127108145701121\n",
      "F1-Score: 0.7125163333862421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71     61349\n",
      "           1       0.65      0.63      0.64     61349\n",
      "           2       0.79      0.78      0.79     61350\n",
      "\n",
      "    accuracy                           0.71    184048\n",
      "   macro avg       0.71      0.71      0.71    184048\n",
      "weighted avg       0.71      0.71      0.71    184048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train_80, y_train_80)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test_20)\n",
    "\n",
    "accuracy = accuracy_score(y_test_20, y_pred_xgb)\n",
    "precision = precision_score(y_test_20, y_pred_xgb, average='weighted')\n",
    "recall = recall_score(y_test_20, y_pred_xgb, average='weighted')\n",
    "f1 = f1_score(y_test_20, y_pred_xgb, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:}\")\n",
    "print(f\"Precision: {precision:}\")\n",
    "print(f\"Recall: {recall:}\")\n",
    "print(f\"F1-Score: {f1:}\")\n",
    "# Evaluate the XGBoost model\n",
    "print(classification_report(y_test_20, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "Accuracy: 0.8463281317917065\n",
      "Precision: 0.8624658314530487\n",
      "Recall: 0.8463281317917065\n",
      "F1-Score: 0.841771334490594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     61349\n",
      "           1       0.78      0.94      0.85     61349\n",
      "           2       0.96      0.66      0.78     61350\n",
      "\n",
      "    accuracy                           0.85    184048\n",
      "   macro avg       0.86      0.85      0.84    184048\n",
      "weighted avg       0.86      0.85      0.84    184048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_80, y_train_80)\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_test_20)\n",
    "\n",
    "print(\"KNN:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_20, y_pred_knn)}\")\n",
    "print(f\"Precision: {precision_score(y_test_20, y_pred_knn, average='weighted')}\")\n",
    "print(f\"Recall: {recall_score(y_test_20, y_pred_knn, average='weighted')}\")\n",
    "print(f\"F1-Score: {f1_score(y_test_20, y_pred_knn, average='weighted')}\")\n",
    "print(classification_report(y_test_20, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting:\n",
      "Accuracy: 0.6862068590802399\n",
      "Precision: 0.6862160926342716\n",
      "Recall: 0.6862068590802399\n",
      "F1-Score: 0.6861218989321649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68     61349\n",
      "           1       0.62      0.60      0.61     61349\n",
      "           2       0.77      0.76      0.76     61350\n",
      "\n",
      "    accuracy                           0.69    184048\n",
      "   macro avg       0.69      0.69      0.69    184048\n",
      "weighted avg       0.69      0.69      0.69    184048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_train_80, y_train_80)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_test_20)\n",
    "\n",
    "print(\"Gradient Boosting:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_20, y_pred_gb)}\")\n",
    "print(f\"Precision: {precision_score(y_test_20, y_pred_gb, average='weighted')}\")\n",
    "print(f\"Recall: {recall_score(y_test_20, y_pred_gb, average='weighted')}\")\n",
    "print(f\"F1-Score: {f1_score(y_test_20, y_pred_gb, average='weighted')}\")\n",
    "print(classification_report(y_test_20, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "CUDA Device Name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a Simple Neural Network Classifier on Top of BERT Embeddings\n",
    "class BERT_Classifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(BERT_Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        x = self.fc1(embeddings)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xinyi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT_Classifier(\n",
       "  (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize Model\n",
    "input_size = X_train_80.shape[1]  # Dimension of BERT embeddings\n",
    "num_classes = len(np.unique(y))  # Number of sentiment classes\n",
    "model = BERT_Classifier(input_size, num_classes)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_80, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_80, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_20, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_20, dtype=torch.long)\n",
    "# Create PyTorch Dataset and DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Function and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.6685, Accuracy: 0.7007\n",
      "Epoch 2/5, Loss: 0.6036, Accuracy: 0.7364\n",
      "Epoch 3/5, Loss: 0.5649, Accuracy: 0.7584\n",
      "Epoch 4/5, Loss: 0.5344, Accuracy: 0.7748\n",
      "Epoch 5/5, Loss: 0.5094, Accuracy: 0.7873\n",
      "Test Accuracy: 0.7864\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for embeddings, labels in train_dataloader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)  \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_dataloader:  \n",
    "        embeddings, labels = embeddings.to(device), labels.to(device) \n",
    "        outputs = model(embeddings) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 0.6687 | Val Loss: 0.6321 | Train Accuracy: 0.7007\n",
      "Epoch 2/5 | Train Loss: 0.6027 | Val Loss: 0.5901 | Train Accuracy: 0.7371\n",
      "Epoch 3/5 | Train Loss: 0.5628 | Val Loss: 0.5641 | Train Accuracy: 0.7597\n",
      "Epoch 4/5 | Train Loss: 0.5323 | Val Loss: 0.5327 | Train Accuracy: 0.7760\n",
      "Epoch 5/5 | Train Loss: 0.5073 | Val Loss: 0.5141 | Train Accuracy: 0.7887\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for embeddings, labels in train_dataloader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_accuracy = correct / total\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels in test_dataloader:\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            outputs = model(embeddings)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(test_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Train Accuracy: {train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Training Loss', color='royalblue')\n",
    "plt.plot(range(1, epochs+1), val_losses, label='Validation Loss', color='tomato')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.4883, Accuracy: 0.7986\n",
      "Epoch 2/10, Loss: 0.4705, Accuracy: 0.8072\n",
      "Epoch 3/10, Loss: 0.4546, Accuracy: 0.8149\n",
      "Epoch 4/10, Loss: 0.4407, Accuracy: 0.8217\n",
      "Epoch 5/10, Loss: 0.4290, Accuracy: 0.8279\n",
      "Epoch 6/10, Loss: 0.4180, Accuracy: 0.8332\n",
      "Epoch 7/10, Loss: 0.4083, Accuracy: 0.8374\n",
      "Epoch 8/10, Loss: 0.3993, Accuracy: 0.8413\n",
      "Epoch 9/10, Loss: 0.3915, Accuracy: 0.8451\n",
      "Epoch 10/10, Loss: 0.3839, Accuracy: 0.8485\n",
      "Test Accuracy: 0.8303\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for embeddings, labels in train_dataloader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)  \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_dataloader:  \n",
    "        embeddings, labels = embeddings.to(device), labels.to(device) \n",
    "        outputs = model(embeddings) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 0.3771, Accuracy: 0.8514\n",
      "Epoch 2/15, Loss: 0.3710, Accuracy: 0.8542\n",
      "Epoch 3/15, Loss: 0.3652, Accuracy: 0.8567\n",
      "Epoch 4/15, Loss: 0.3599, Accuracy: 0.8589\n",
      "Epoch 5/15, Loss: 0.3547, Accuracy: 0.8615\n",
      "Epoch 6/15, Loss: 0.3499, Accuracy: 0.8634\n",
      "Epoch 7/15, Loss: 0.3452, Accuracy: 0.8651\n",
      "Epoch 8/15, Loss: 0.3413, Accuracy: 0.8672\n",
      "Epoch 9/15, Loss: 0.3372, Accuracy: 0.8688\n",
      "Epoch 10/15, Loss: 0.3330, Accuracy: 0.8703\n",
      "Epoch 11/15, Loss: 0.3297, Accuracy: 0.8714\n",
      "Epoch 12/15, Loss: 0.3264, Accuracy: 0.8734\n",
      "Epoch 13/15, Loss: 0.3228, Accuracy: 0.8745\n",
      "Epoch 14/15, Loss: 0.3196, Accuracy: 0.8761\n",
      "Epoch 15/15, Loss: 0.3166, Accuracy: 0.8774\n",
      "Test Accuracy: 0.8507\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for embeddings, labels in train_dataloader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)  \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_dataloader:  \n",
    "        embeddings, labels = embeddings.to(device), labels.to(device) \n",
    "        outputs = model(embeddings) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.3136, Accuracy: 0.8789\n",
      "Epoch 2/20, Loss: 0.3114, Accuracy: 0.8796\n",
      "Epoch 3/20, Loss: 0.3085, Accuracy: 0.8808\n",
      "Epoch 4/20, Loss: 0.3057, Accuracy: 0.8816\n",
      "Epoch 5/20, Loss: 0.3037, Accuracy: 0.8827\n",
      "Epoch 6/20, Loss: 0.3010, Accuracy: 0.8837\n",
      "Epoch 7/20, Loss: 0.2991, Accuracy: 0.8847\n",
      "Epoch 8/20, Loss: 0.2966, Accuracy: 0.8852\n",
      "Epoch 9/20, Loss: 0.2947, Accuracy: 0.8862\n",
      "Epoch 10/20, Loss: 0.2926, Accuracy: 0.8872\n",
      "Epoch 11/20, Loss: 0.2908, Accuracy: 0.8875\n",
      "Epoch 12/20, Loss: 0.2888, Accuracy: 0.8888\n",
      "Epoch 13/20, Loss: 0.2872, Accuracy: 0.8894\n",
      "Epoch 14/20, Loss: 0.2855, Accuracy: 0.8900\n",
      "Epoch 15/20, Loss: 0.2835, Accuracy: 0.8908\n",
      "Epoch 16/20, Loss: 0.2817, Accuracy: 0.8917\n",
      "Epoch 17/20, Loss: 0.2801, Accuracy: 0.8919\n",
      "Epoch 18/20, Loss: 0.2787, Accuracy: 0.8925\n",
      "Epoch 19/20, Loss: 0.2770, Accuracy: 0.8935\n",
      "Epoch 20/20, Loss: 0.2751, Accuracy: 0.8939\n",
      "Test Accuracy: 0.8577\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for embeddings, labels in train_dataloader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)  \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_dataloader:  \n",
    "        embeddings, labels = embeddings.to(device), labels.to(device) \n",
    "        outputs = model(embeddings) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.2742, Accuracy: 0.8947\n",
      "Epoch 2/30, Loss: 0.2726, Accuracy: 0.8950\n",
      "Epoch 3/30, Loss: 0.2709, Accuracy: 0.8959\n",
      "Epoch 4/30, Loss: 0.2695, Accuracy: 0.8963\n",
      "Epoch 5/30, Loss: 0.2685, Accuracy: 0.8964\n",
      "Epoch 6/30, Loss: 0.2672, Accuracy: 0.8976\n",
      "Epoch 7/30, Loss: 0.2660, Accuracy: 0.8975\n",
      "Epoch 8/30, Loss: 0.2647, Accuracy: 0.8982\n",
      "Epoch 9/30, Loss: 0.2632, Accuracy: 0.8990\n",
      "Epoch 10/30, Loss: 0.2626, Accuracy: 0.8987\n",
      "Epoch 11/30, Loss: 0.2609, Accuracy: 0.8996\n",
      "Epoch 12/30, Loss: 0.2602, Accuracy: 0.9000\n",
      "Epoch 13/30, Loss: 0.2589, Accuracy: 0.9004\n",
      "Epoch 14/30, Loss: 0.2577, Accuracy: 0.9010\n",
      "Epoch 15/30, Loss: 0.2569, Accuracy: 0.9014\n",
      "Epoch 16/30, Loss: 0.2555, Accuracy: 0.9019\n",
      "Epoch 17/30, Loss: 0.2550, Accuracy: 0.9022\n",
      "Epoch 18/30, Loss: 0.2539, Accuracy: 0.9024\n",
      "Epoch 19/30, Loss: 0.2520, Accuracy: 0.9034\n",
      "Epoch 20/30, Loss: 0.2518, Accuracy: 0.9035\n",
      "Epoch 21/30, Loss: 0.2507, Accuracy: 0.9036\n",
      "Epoch 22/30, Loss: 0.2496, Accuracy: 0.9043\n",
      "Epoch 23/30, Loss: 0.2489, Accuracy: 0.9046\n",
      "Epoch 24/30, Loss: 0.2478, Accuracy: 0.9050\n",
      "Epoch 25/30, Loss: 0.2467, Accuracy: 0.9052\n",
      "Epoch 26/30, Loss: 0.2467, Accuracy: 0.9054\n",
      "Epoch 27/30, Loss: 0.2453, Accuracy: 0.9060\n",
      "Epoch 28/30, Loss: 0.2440, Accuracy: 0.9057\n",
      "Epoch 29/30, Loss: 0.2438, Accuracy: 0.9063\n",
      "Epoch 30/30, Loss: 0.2433, Accuracy: 0.9064\n",
      "Test Accuracy: 0.8780\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for embeddings, labels in train_dataloader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)  \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_dataloader:  \n",
    "        embeddings, labels = embeddings.to(device), labels.to(device) \n",
    "        outputs = model(embeddings) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 0.2424, Accuracy: 0.9069\n",
      "Epoch 2/40, Loss: 0.2412, Accuracy: 0.9077\n",
      "Epoch 3/40, Loss: 0.2404, Accuracy: 0.9078\n",
      "Epoch 4/40, Loss: 0.2400, Accuracy: 0.9080\n",
      "Epoch 5/40, Loss: 0.2392, Accuracy: 0.9082\n",
      "Epoch 6/40, Loss: 0.2380, Accuracy: 0.9087\n",
      "Epoch 7/40, Loss: 0.2377, Accuracy: 0.9088\n",
      "Epoch 8/40, Loss: 0.2370, Accuracy: 0.9090\n",
      "Epoch 9/40, Loss: 0.2362, Accuracy: 0.9091\n",
      "Epoch 10/40, Loss: 0.2354, Accuracy: 0.9098\n",
      "Epoch 11/40, Loss: 0.2347, Accuracy: 0.9096\n",
      "Epoch 12/40, Loss: 0.2341, Accuracy: 0.9102\n",
      "Epoch 13/40, Loss: 0.2334, Accuracy: 0.9103\n",
      "Epoch 14/40, Loss: 0.2330, Accuracy: 0.9104\n",
      "Epoch 15/40, Loss: 0.2321, Accuracy: 0.9110\n",
      "Epoch 16/40, Loss: 0.2314, Accuracy: 0.9115\n",
      "Epoch 17/40, Loss: 0.2310, Accuracy: 0.9113\n",
      "Epoch 18/40, Loss: 0.2302, Accuracy: 0.9113\n",
      "Epoch 19/40, Loss: 0.2295, Accuracy: 0.9120\n",
      "Epoch 20/40, Loss: 0.2288, Accuracy: 0.9117\n",
      "Epoch 21/40, Loss: 0.2284, Accuracy: 0.9126\n",
      "Epoch 22/40, Loss: 0.2278, Accuracy: 0.9125\n",
      "Epoch 23/40, Loss: 0.2275, Accuracy: 0.9126\n",
      "Epoch 24/40, Loss: 0.2273, Accuracy: 0.9124\n",
      "Epoch 25/40, Loss: 0.2260, Accuracy: 0.9131\n",
      "Epoch 26/40, Loss: 0.2256, Accuracy: 0.9134\n",
      "Epoch 27/40, Loss: 0.2250, Accuracy: 0.9136\n",
      "Epoch 28/40, Loss: 0.2245, Accuracy: 0.9137\n",
      "Epoch 29/40, Loss: 0.2242, Accuracy: 0.9133\n",
      "Epoch 30/40, Loss: 0.2236, Accuracy: 0.9138\n",
      "Epoch 31/40, Loss: 0.2232, Accuracy: 0.9142\n",
      "Epoch 32/40, Loss: 0.2226, Accuracy: 0.9141\n",
      "Epoch 33/40, Loss: 0.2221, Accuracy: 0.9147\n",
      "Epoch 34/40, Loss: 0.2213, Accuracy: 0.9151\n",
      "Epoch 35/40, Loss: 0.2211, Accuracy: 0.9153\n",
      "Epoch 36/40, Loss: 0.2201, Accuracy: 0.9154\n",
      "Epoch 37/40, Loss: 0.2203, Accuracy: 0.9153\n",
      "Epoch 38/40, Loss: 0.2193, Accuracy: 0.9158\n",
      "Epoch 39/40, Loss: 0.2190, Accuracy: 0.9156\n",
      "Epoch 40/40, Loss: 0.2182, Accuracy: 0.9160\n",
      "Test Accuracy: 0.8774\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 40\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for embeddings, labels in train_dataloader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)  \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_dataloader:  \n",
    "        embeddings, labels = embeddings.to(device), labels.to(device) \n",
    "        outputs = model(embeddings) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.2179, Accuracy: 0.9164\n",
      "Epoch 2/50, Loss: 0.2173, Accuracy: 0.9162\n",
      "Epoch 3/50, Loss: 0.2169, Accuracy: 0.9161\n",
      "Epoch 4/50, Loss: 0.2164, Accuracy: 0.9172\n",
      "Epoch 5/50, Loss: 0.2163, Accuracy: 0.9167\n",
      "Epoch 6/50, Loss: 0.2156, Accuracy: 0.9168\n",
      "Epoch 7/50, Loss: 0.2152, Accuracy: 0.9172\n",
      "Epoch 8/50, Loss: 0.2148, Accuracy: 0.9172\n",
      "Epoch 9/50, Loss: 0.2142, Accuracy: 0.9177\n",
      "Epoch 10/50, Loss: 0.2141, Accuracy: 0.9176\n",
      "Epoch 11/50, Loss: 0.2133, Accuracy: 0.9181\n",
      "Epoch 12/50, Loss: 0.2129, Accuracy: 0.9183\n",
      "Epoch 13/50, Loss: 0.2125, Accuracy: 0.9183\n",
      "Epoch 14/50, Loss: 0.2119, Accuracy: 0.9182\n",
      "Epoch 15/50, Loss: 0.2118, Accuracy: 0.9183\n",
      "Epoch 16/50, Loss: 0.2114, Accuracy: 0.9182\n",
      "Epoch 17/50, Loss: 0.2104, Accuracy: 0.9191\n",
      "Epoch 18/50, Loss: 0.2106, Accuracy: 0.9188\n",
      "Epoch 19/50, Loss: 0.2100, Accuracy: 0.9191\n",
      "Epoch 20/50, Loss: 0.2097, Accuracy: 0.9191\n",
      "Epoch 21/50, Loss: 0.2096, Accuracy: 0.9192\n",
      "Epoch 22/50, Loss: 0.2085, Accuracy: 0.9197\n",
      "Epoch 23/50, Loss: 0.2087, Accuracy: 0.9196\n",
      "Epoch 24/50, Loss: 0.2081, Accuracy: 0.9196\n",
      "Epoch 25/50, Loss: 0.2079, Accuracy: 0.9200\n",
      "Epoch 26/50, Loss: 0.2072, Accuracy: 0.9200\n",
      "Epoch 27/50, Loss: 0.2072, Accuracy: 0.9202\n",
      "Epoch 28/50, Loss: 0.2071, Accuracy: 0.9200\n",
      "Epoch 29/50, Loss: 0.2069, Accuracy: 0.9206\n",
      "Epoch 30/50, Loss: 0.2057, Accuracy: 0.9208\n",
      "Epoch 31/50, Loss: 0.2056, Accuracy: 0.9211\n",
      "Epoch 32/50, Loss: 0.2049, Accuracy: 0.9210\n",
      "Epoch 33/50, Loss: 0.2048, Accuracy: 0.9211\n",
      "Epoch 34/50, Loss: 0.2049, Accuracy: 0.9210\n",
      "Epoch 35/50, Loss: 0.2044, Accuracy: 0.9211\n",
      "Epoch 36/50, Loss: 0.2038, Accuracy: 0.9213\n",
      "Epoch 37/50, Loss: 0.2037, Accuracy: 0.9217\n",
      "Epoch 38/50, Loss: 0.2032, Accuracy: 0.9217\n",
      "Epoch 39/50, Loss: 0.2031, Accuracy: 0.9217\n",
      "Epoch 40/50, Loss: 0.2027, Accuracy: 0.9223\n",
      "Epoch 41/50, Loss: 0.2025, Accuracy: 0.9217\n",
      "Epoch 42/50, Loss: 0.2022, Accuracy: 0.9220\n",
      "Epoch 43/50, Loss: 0.2023, Accuracy: 0.9220\n",
      "Epoch 44/50, Loss: 0.2014, Accuracy: 0.9223\n",
      "Epoch 45/50, Loss: 0.2012, Accuracy: 0.9222\n",
      "Epoch 46/50, Loss: 0.2008, Accuracy: 0.9226\n",
      "Epoch 47/50, Loss: 0.2003, Accuracy: 0.9228\n",
      "Epoch 48/50, Loss: 0.2002, Accuracy: 0.9228\n",
      "Epoch 49/50, Loss: 0.1997, Accuracy: 0.9234\n",
      "Epoch 50/50, Loss: 0.1998, Accuracy: 0.9230\n",
      "Test Accuracy: 0.8792\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for embeddings, labels in train_dataloader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)  \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_dataloader:  \n",
    "        embeddings, labels = embeddings.to(device), labels.to(device) \n",
    "        outputs = model(embeddings) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60, Loss: 0.1994, Accuracy: 0.9233\n",
      "Epoch 2/60, Loss: 0.1992, Accuracy: 0.9229\n",
      "Epoch 3/60, Loss: 0.1985, Accuracy: 0.9234\n",
      "Epoch 4/60, Loss: 0.1986, Accuracy: 0.9237\n",
      "Epoch 5/60, Loss: 0.1978, Accuracy: 0.9236\n",
      "Epoch 6/60, Loss: 0.1979, Accuracy: 0.9239\n",
      "Epoch 7/60, Loss: 0.1975, Accuracy: 0.9236\n",
      "Epoch 8/60, Loss: 0.1970, Accuracy: 0.9242\n",
      "Epoch 9/60, Loss: 0.1969, Accuracy: 0.9239\n",
      "Epoch 10/60, Loss: 0.1964, Accuracy: 0.9243\n",
      "Epoch 11/60, Loss: 0.1962, Accuracy: 0.9245\n",
      "Epoch 12/60, Loss: 0.1962, Accuracy: 0.9241\n",
      "Epoch 13/60, Loss: 0.1960, Accuracy: 0.9245\n",
      "Epoch 14/60, Loss: 0.1957, Accuracy: 0.9246\n",
      "Epoch 15/60, Loss: 0.1956, Accuracy: 0.9244\n",
      "Epoch 16/60, Loss: 0.1950, Accuracy: 0.9248\n",
      "Epoch 17/60, Loss: 0.1950, Accuracy: 0.9246\n",
      "Epoch 18/60, Loss: 0.1945, Accuracy: 0.9249\n",
      "Epoch 19/60, Loss: 0.1941, Accuracy: 0.9252\n",
      "Epoch 20/60, Loss: 0.1937, Accuracy: 0.9252\n",
      "Epoch 21/60, Loss: 0.1936, Accuracy: 0.9251\n",
      "Epoch 22/60, Loss: 0.1937, Accuracy: 0.9254\n",
      "Epoch 23/60, Loss: 0.1927, Accuracy: 0.9256\n",
      "Epoch 24/60, Loss: 0.1927, Accuracy: 0.9260\n",
      "Epoch 25/60, Loss: 0.1925, Accuracy: 0.9254\n",
      "Epoch 26/60, Loss: 0.1922, Accuracy: 0.9257\n",
      "Epoch 27/60, Loss: 0.1920, Accuracy: 0.9263\n",
      "Epoch 28/60, Loss: 0.1918, Accuracy: 0.9261\n",
      "Epoch 29/60, Loss: 0.1919, Accuracy: 0.9259\n",
      "Epoch 30/60, Loss: 0.1912, Accuracy: 0.9260\n",
      "Epoch 31/60, Loss: 0.1909, Accuracy: 0.9262\n",
      "Epoch 32/60, Loss: 0.1907, Accuracy: 0.9267\n",
      "Epoch 33/60, Loss: 0.1907, Accuracy: 0.9263\n",
      "Epoch 34/60, Loss: 0.1906, Accuracy: 0.9264\n",
      "Epoch 35/60, Loss: 0.1901, Accuracy: 0.9268\n",
      "Epoch 36/60, Loss: 0.1901, Accuracy: 0.9264\n",
      "Epoch 37/60, Loss: 0.1897, Accuracy: 0.9265\n",
      "Epoch 38/60, Loss: 0.1896, Accuracy: 0.9270\n",
      "Epoch 39/60, Loss: 0.1891, Accuracy: 0.9270\n",
      "Epoch 40/60, Loss: 0.1891, Accuracy: 0.9270\n",
      "Epoch 41/60, Loss: 0.1885, Accuracy: 0.9272\n",
      "Epoch 42/60, Loss: 0.1887, Accuracy: 0.9271\n",
      "Epoch 43/60, Loss: 0.1879, Accuracy: 0.9276\n",
      "Epoch 44/60, Loss: 0.1883, Accuracy: 0.9272\n",
      "Epoch 45/60, Loss: 0.1881, Accuracy: 0.9273\n",
      "Epoch 46/60, Loss: 0.1880, Accuracy: 0.9275\n",
      "Epoch 47/60, Loss: 0.1877, Accuracy: 0.9274\n",
      "Epoch 48/60, Loss: 0.1869, Accuracy: 0.9281\n",
      "Epoch 49/60, Loss: 0.1869, Accuracy: 0.9275\n",
      "Epoch 50/60, Loss: 0.1870, Accuracy: 0.9277\n",
      "Epoch 51/60, Loss: 0.1865, Accuracy: 0.9280\n",
      "Epoch 52/60, Loss: 0.1861, Accuracy: 0.9281\n",
      "Epoch 53/60, Loss: 0.1860, Accuracy: 0.9280\n",
      "Epoch 54/60, Loss: 0.1858, Accuracy: 0.9280\n",
      "Epoch 55/60, Loss: 0.1855, Accuracy: 0.9282\n",
      "Epoch 56/60, Loss: 0.1853, Accuracy: 0.9285\n",
      "Epoch 57/60, Loss: 0.1850, Accuracy: 0.9284\n",
      "Epoch 58/60, Loss: 0.1849, Accuracy: 0.9285\n",
      "Epoch 59/60, Loss: 0.1848, Accuracy: 0.9286\n",
      "Epoch 60/60, Loss: 0.1847, Accuracy: 0.9286\n",
      "Test Accuracy: 0.8871\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 60\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for embeddings, labels in train_dataloader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)  \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_dataloader:  \n",
    "        embeddings, labels = embeddings.to(device), labels.to(device) \n",
    "        outputs = model(embeddings) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70, Loss: 0.1845, Accuracy: 0.9287\n",
      "Epoch 2/70, Loss: 0.1840, Accuracy: 0.9287\n",
      "Epoch 3/70, Loss: 0.1838, Accuracy: 0.9292\n",
      "Epoch 4/70, Loss: 0.1834, Accuracy: 0.9291\n",
      "Epoch 5/70, Loss: 0.1834, Accuracy: 0.9289\n",
      "Epoch 6/70, Loss: 0.1836, Accuracy: 0.9290\n",
      "Epoch 7/70, Loss: 0.1829, Accuracy: 0.9294\n",
      "Epoch 8/70, Loss: 0.1831, Accuracy: 0.9293\n",
      "Epoch 9/70, Loss: 0.1828, Accuracy: 0.9294\n",
      "Epoch 10/70, Loss: 0.1827, Accuracy: 0.9291\n",
      "Epoch 11/70, Loss: 0.1825, Accuracy: 0.9291\n",
      "Epoch 12/70, Loss: 0.1822, Accuracy: 0.9293\n",
      "Epoch 13/70, Loss: 0.1821, Accuracy: 0.9293\n",
      "Epoch 14/70, Loss: 0.1820, Accuracy: 0.9294\n",
      "Epoch 15/70, Loss: 0.1818, Accuracy: 0.9296\n",
      "Epoch 16/70, Loss: 0.1812, Accuracy: 0.9300\n",
      "Epoch 17/70, Loss: 0.1813, Accuracy: 0.9298\n",
      "Epoch 18/70, Loss: 0.1815, Accuracy: 0.9296\n",
      "Epoch 19/70, Loss: 0.1812, Accuracy: 0.9298\n",
      "Epoch 20/70, Loss: 0.1807, Accuracy: 0.9299\n",
      "Epoch 21/70, Loss: 0.1804, Accuracy: 0.9303\n",
      "Epoch 22/70, Loss: 0.1804, Accuracy: 0.9300\n",
      "Epoch 23/70, Loss: 0.1802, Accuracy: 0.9302\n",
      "Epoch 24/70, Loss: 0.1798, Accuracy: 0.9303\n",
      "Epoch 25/70, Loss: 0.1797, Accuracy: 0.9303\n",
      "Epoch 26/70, Loss: 0.1796, Accuracy: 0.9306\n",
      "Epoch 27/70, Loss: 0.1793, Accuracy: 0.9306\n",
      "Epoch 28/70, Loss: 0.1794, Accuracy: 0.9303\n",
      "Epoch 29/70, Loss: 0.1787, Accuracy: 0.9306\n",
      "Epoch 30/70, Loss: 0.1789, Accuracy: 0.9305\n",
      "Epoch 31/70, Loss: 0.1785, Accuracy: 0.9308\n",
      "Epoch 32/70, Loss: 0.1785, Accuracy: 0.9310\n",
      "Epoch 33/70, Loss: 0.1784, Accuracy: 0.9308\n",
      "Epoch 34/70, Loss: 0.1781, Accuracy: 0.9308\n",
      "Epoch 35/70, Loss: 0.1779, Accuracy: 0.9312\n",
      "Epoch 36/70, Loss: 0.1775, Accuracy: 0.9313\n",
      "Epoch 37/70, Loss: 0.1776, Accuracy: 0.9314\n",
      "Epoch 38/70, Loss: 0.1775, Accuracy: 0.9313\n",
      "Epoch 39/70, Loss: 0.1774, Accuracy: 0.9312\n",
      "Epoch 40/70, Loss: 0.1771, Accuracy: 0.9316\n",
      "Epoch 41/70, Loss: 0.1769, Accuracy: 0.9314\n",
      "Epoch 42/70, Loss: 0.1770, Accuracy: 0.9313\n",
      "Epoch 43/70, Loss: 0.1763, Accuracy: 0.9318\n",
      "Epoch 44/70, Loss: 0.1764, Accuracy: 0.9315\n",
      "Epoch 45/70, Loss: 0.1764, Accuracy: 0.9317\n",
      "Epoch 46/70, Loss: 0.1763, Accuracy: 0.9313\n",
      "Epoch 47/70, Loss: 0.1761, Accuracy: 0.9314\n",
      "Epoch 48/70, Loss: 0.1761, Accuracy: 0.9316\n",
      "Epoch 49/70, Loss: 0.1755, Accuracy: 0.9320\n",
      "Epoch 50/70, Loss: 0.1752, Accuracy: 0.9321\n",
      "Epoch 51/70, Loss: 0.1754, Accuracy: 0.9320\n",
      "Epoch 52/70, Loss: 0.1750, Accuracy: 0.9321\n",
      "Epoch 53/70, Loss: 0.1749, Accuracy: 0.9322\n",
      "Epoch 54/70, Loss: 0.1747, Accuracy: 0.9321\n",
      "Epoch 55/70, Loss: 0.1749, Accuracy: 0.9320\n",
      "Epoch 56/70, Loss: 0.1744, Accuracy: 0.9325\n",
      "Epoch 57/70, Loss: 0.1743, Accuracy: 0.9322\n",
      "Epoch 58/70, Loss: 0.1741, Accuracy: 0.9327\n",
      "Epoch 59/70, Loss: 0.1736, Accuracy: 0.9328\n",
      "Epoch 60/70, Loss: 0.1739, Accuracy: 0.9324\n",
      "Epoch 61/70, Loss: 0.1740, Accuracy: 0.9323\n",
      "Epoch 62/70, Loss: 0.1734, Accuracy: 0.9328\n",
      "Epoch 63/70, Loss: 0.1735, Accuracy: 0.9324\n",
      "Epoch 64/70, Loss: 0.1735, Accuracy: 0.9328\n",
      "Epoch 65/70, Loss: 0.1733, Accuracy: 0.9326\n",
      "Epoch 66/70, Loss: 0.1730, Accuracy: 0.9327\n",
      "Epoch 67/70, Loss: 0.1728, Accuracy: 0.9329\n",
      "Epoch 68/70, Loss: 0.1727, Accuracy: 0.9329\n",
      "Epoch 69/70, Loss: 0.1727, Accuracy: 0.9331\n",
      "Epoch 70/70, Loss: 0.1727, Accuracy: 0.9329\n",
      "Test Accuracy: 0.8875\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 70\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for embeddings, labels in train_dataloader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)  \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_dataloader:  \n",
    "        embeddings, labels = embeddings.to(device), labels.to(device) \n",
    "        outputs = model(embeddings) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80, Loss: 0.1722, Accuracy: 0.9334\n",
      "Epoch 2/80, Loss: 0.1724, Accuracy: 0.9331\n",
      "Epoch 3/80, Loss: 0.1721, Accuracy: 0.9333\n",
      "Epoch 4/80, Loss: 0.1716, Accuracy: 0.9334\n",
      "Epoch 5/80, Loss: 0.1718, Accuracy: 0.9335\n",
      "Epoch 6/80, Loss: 0.1716, Accuracy: 0.9331\n",
      "Epoch 7/80, Loss: 0.1716, Accuracy: 0.9336\n",
      "Epoch 8/80, Loss: 0.1712, Accuracy: 0.9335\n",
      "Epoch 9/80, Loss: 0.1715, Accuracy: 0.9335\n",
      "Epoch 10/80, Loss: 0.1712, Accuracy: 0.9334\n",
      "Epoch 11/80, Loss: 0.1712, Accuracy: 0.9332\n",
      "Epoch 12/80, Loss: 0.1709, Accuracy: 0.9335\n",
      "Epoch 13/80, Loss: 0.1705, Accuracy: 0.9338\n",
      "Epoch 14/80, Loss: 0.1707, Accuracy: 0.9340\n",
      "Epoch 15/80, Loss: 0.1701, Accuracy: 0.9338\n",
      "Epoch 16/80, Loss: 0.1705, Accuracy: 0.9338\n",
      "Epoch 17/80, Loss: 0.1701, Accuracy: 0.9340\n",
      "Epoch 18/80, Loss: 0.1699, Accuracy: 0.9341\n",
      "Epoch 19/80, Loss: 0.1700, Accuracy: 0.9339\n",
      "Epoch 20/80, Loss: 0.1697, Accuracy: 0.9340\n",
      "Epoch 21/80, Loss: 0.1698, Accuracy: 0.9340\n",
      "Epoch 22/80, Loss: 0.1694, Accuracy: 0.9340\n",
      "Epoch 23/80, Loss: 0.1694, Accuracy: 0.9340\n",
      "Epoch 24/80, Loss: 0.1690, Accuracy: 0.9342\n",
      "Epoch 25/80, Loss: 0.1689, Accuracy: 0.9342\n",
      "Epoch 26/80, Loss: 0.1689, Accuracy: 0.9343\n",
      "Epoch 27/80, Loss: 0.1684, Accuracy: 0.9346\n",
      "Epoch 28/80, Loss: 0.1684, Accuracy: 0.9347\n",
      "Epoch 29/80, Loss: 0.1687, Accuracy: 0.9346\n",
      "Epoch 30/80, Loss: 0.1684, Accuracy: 0.9346\n",
      "Epoch 31/80, Loss: 0.1682, Accuracy: 0.9346\n",
      "Epoch 32/80, Loss: 0.1681, Accuracy: 0.9346\n",
      "Epoch 33/80, Loss: 0.1679, Accuracy: 0.9346\n",
      "Epoch 34/80, Loss: 0.1677, Accuracy: 0.9347\n",
      "Epoch 35/80, Loss: 0.1677, Accuracy: 0.9349\n",
      "Epoch 36/80, Loss: 0.1676, Accuracy: 0.9349\n",
      "Epoch 37/80, Loss: 0.1673, Accuracy: 0.9348\n",
      "Epoch 38/80, Loss: 0.1674, Accuracy: 0.9350\n",
      "Epoch 39/80, Loss: 0.1670, Accuracy: 0.9350\n",
      "Epoch 40/80, Loss: 0.1671, Accuracy: 0.9349\n",
      "Epoch 41/80, Loss: 0.1670, Accuracy: 0.9350\n",
      "Epoch 42/80, Loss: 0.1668, Accuracy: 0.9351\n",
      "Epoch 43/80, Loss: 0.1667, Accuracy: 0.9352\n",
      "Epoch 44/80, Loss: 0.1666, Accuracy: 0.9348\n",
      "Epoch 45/80, Loss: 0.1664, Accuracy: 0.9350\n",
      "Epoch 46/80, Loss: 0.1666, Accuracy: 0.9348\n",
      "Epoch 47/80, Loss: 0.1662, Accuracy: 0.9351\n",
      "Epoch 48/80, Loss: 0.1661, Accuracy: 0.9353\n",
      "Epoch 49/80, Loss: 0.1657, Accuracy: 0.9355\n",
      "Epoch 50/80, Loss: 0.1659, Accuracy: 0.9355\n",
      "Epoch 51/80, Loss: 0.1654, Accuracy: 0.9354\n",
      "Epoch 52/80, Loss: 0.1655, Accuracy: 0.9354\n",
      "Epoch 53/80, Loss: 0.1655, Accuracy: 0.9356\n",
      "Epoch 54/80, Loss: 0.1654, Accuracy: 0.9358\n",
      "Epoch 55/80, Loss: 0.1653, Accuracy: 0.9357\n",
      "Epoch 56/80, Loss: 0.1652, Accuracy: 0.9358\n",
      "Epoch 57/80, Loss: 0.1652, Accuracy: 0.9359\n",
      "Epoch 58/80, Loss: 0.1651, Accuracy: 0.9358\n",
      "Epoch 59/80, Loss: 0.1647, Accuracy: 0.9359\n",
      "Epoch 60/80, Loss: 0.1647, Accuracy: 0.9357\n",
      "Epoch 61/80, Loss: 0.1648, Accuracy: 0.9358\n",
      "Epoch 62/80, Loss: 0.1641, Accuracy: 0.9359\n",
      "Epoch 63/80, Loss: 0.1646, Accuracy: 0.9359\n",
      "Epoch 64/80, Loss: 0.1642, Accuracy: 0.9363\n",
      "Epoch 65/80, Loss: 0.1641, Accuracy: 0.9364\n",
      "Epoch 66/80, Loss: 0.1642, Accuracy: 0.9360\n",
      "Epoch 67/80, Loss: 0.1641, Accuracy: 0.9358\n",
      "Epoch 68/80, Loss: 0.1637, Accuracy: 0.9365\n",
      "Epoch 69/80, Loss: 0.1634, Accuracy: 0.9362\n",
      "Epoch 70/80, Loss: 0.1634, Accuracy: 0.9365\n",
      "Epoch 71/80, Loss: 0.1636, Accuracy: 0.9363\n",
      "Epoch 72/80, Loss: 0.1635, Accuracy: 0.9362\n",
      "Epoch 73/80, Loss: 0.1632, Accuracy: 0.9365\n",
      "Epoch 74/80, Loss: 0.1629, Accuracy: 0.9366\n",
      "Epoch 75/80, Loss: 0.1629, Accuracy: 0.9364\n",
      "Epoch 76/80, Loss: 0.1627, Accuracy: 0.9365\n",
      "Epoch 77/80, Loss: 0.1627, Accuracy: 0.9367\n",
      "Epoch 78/80, Loss: 0.1627, Accuracy: 0.9365\n",
      "Epoch 79/80, Loss: 0.1626, Accuracy: 0.9368\n",
      "Epoch 80/80, Loss: 0.1624, Accuracy: 0.9366\n",
      "Test Accuracy: 0.8820\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 80\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for embeddings, labels in train_dataloader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)  \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_dataloader:  \n",
    "        embeddings, labels = embeddings.to(device), labels.to(device) \n",
    "        outputs = model(embeddings) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90, Loss: 0.1626, Accuracy: 0.9368\n",
      "Epoch 2/90, Loss: 0.1621, Accuracy: 0.9368\n",
      "Epoch 3/90, Loss: 0.1621, Accuracy: 0.9368\n",
      "Epoch 4/90, Loss: 0.1622, Accuracy: 0.9367\n",
      "Epoch 5/90, Loss: 0.1621, Accuracy: 0.9368\n",
      "Epoch 6/90, Loss: 0.1617, Accuracy: 0.9371\n",
      "Epoch 7/90, Loss: 0.1614, Accuracy: 0.9372\n",
      "Epoch 8/90, Loss: 0.1618, Accuracy: 0.9368\n",
      "Epoch 9/90, Loss: 0.1613, Accuracy: 0.9372\n",
      "Epoch 10/90, Loss: 0.1615, Accuracy: 0.9371\n",
      "Epoch 11/90, Loss: 0.1610, Accuracy: 0.9373\n",
      "Epoch 12/90, Loss: 0.1612, Accuracy: 0.9373\n",
      "Epoch 13/90, Loss: 0.1610, Accuracy: 0.9374\n",
      "Epoch 14/90, Loss: 0.1607, Accuracy: 0.9374\n",
      "Epoch 15/90, Loss: 0.1606, Accuracy: 0.9372\n",
      "Epoch 16/90, Loss: 0.1606, Accuracy: 0.9373\n",
      "Epoch 17/90, Loss: 0.1607, Accuracy: 0.9374\n",
      "Epoch 18/90, Loss: 0.1604, Accuracy: 0.9376\n",
      "Epoch 19/90, Loss: 0.1604, Accuracy: 0.9373\n",
      "Epoch 20/90, Loss: 0.1604, Accuracy: 0.9374\n",
      "Epoch 21/90, Loss: 0.1600, Accuracy: 0.9377\n",
      "Epoch 22/90, Loss: 0.1602, Accuracy: 0.9376\n",
      "Epoch 23/90, Loss: 0.1601, Accuracy: 0.9375\n",
      "Epoch 24/90, Loss: 0.1596, Accuracy: 0.9379\n",
      "Epoch 25/90, Loss: 0.1598, Accuracy: 0.9378\n",
      "Epoch 26/90, Loss: 0.1596, Accuracy: 0.9376\n",
      "Epoch 27/90, Loss: 0.1596, Accuracy: 0.9376\n",
      "Epoch 28/90, Loss: 0.1595, Accuracy: 0.9377\n",
      "Epoch 29/90, Loss: 0.1593, Accuracy: 0.9377\n",
      "Epoch 30/90, Loss: 0.1594, Accuracy: 0.9380\n",
      "Epoch 31/90, Loss: 0.1589, Accuracy: 0.9380\n",
      "Epoch 32/90, Loss: 0.1591, Accuracy: 0.9380\n",
      "Epoch 33/90, Loss: 0.1590, Accuracy: 0.9379\n",
      "Epoch 34/90, Loss: 0.1590, Accuracy: 0.9380\n",
      "Epoch 35/90, Loss: 0.1588, Accuracy: 0.9380\n",
      "Epoch 36/90, Loss: 0.1583, Accuracy: 0.9382\n",
      "Epoch 37/90, Loss: 0.1587, Accuracy: 0.9380\n",
      "Epoch 38/90, Loss: 0.1587, Accuracy: 0.9381\n",
      "Epoch 39/90, Loss: 0.1583, Accuracy: 0.9385\n",
      "Epoch 40/90, Loss: 0.1584, Accuracy: 0.9384\n",
      "Epoch 41/90, Loss: 0.1579, Accuracy: 0.9383\n",
      "Epoch 42/90, Loss: 0.1580, Accuracy: 0.9381\n",
      "Epoch 43/90, Loss: 0.1579, Accuracy: 0.9384\n",
      "Epoch 44/90, Loss: 0.1579, Accuracy: 0.9383\n",
      "Epoch 45/90, Loss: 0.1578, Accuracy: 0.9385\n",
      "Epoch 46/90, Loss: 0.1576, Accuracy: 0.9387\n",
      "Epoch 47/90, Loss: 0.1575, Accuracy: 0.9383\n",
      "Epoch 48/90, Loss: 0.1575, Accuracy: 0.9386\n",
      "Epoch 49/90, Loss: 0.1575, Accuracy: 0.9386\n",
      "Epoch 50/90, Loss: 0.1576, Accuracy: 0.9387\n",
      "Epoch 51/90, Loss: 0.1573, Accuracy: 0.9386\n",
      "Epoch 52/90, Loss: 0.1573, Accuracy: 0.9385\n",
      "Epoch 53/90, Loss: 0.1571, Accuracy: 0.9385\n",
      "Epoch 54/90, Loss: 0.1570, Accuracy: 0.9387\n",
      "Epoch 55/90, Loss: 0.1569, Accuracy: 0.9387\n",
      "Epoch 56/90, Loss: 0.1569, Accuracy: 0.9386\n",
      "Epoch 57/90, Loss: 0.1567, Accuracy: 0.9384\n",
      "Epoch 58/90, Loss: 0.1569, Accuracy: 0.9389\n",
      "Epoch 59/90, Loss: 0.1566, Accuracy: 0.9390\n",
      "Epoch 60/90, Loss: 0.1566, Accuracy: 0.9389\n",
      "Epoch 61/90, Loss: 0.1566, Accuracy: 0.9391\n",
      "Epoch 62/90, Loss: 0.1562, Accuracy: 0.9388\n",
      "Epoch 63/90, Loss: 0.1561, Accuracy: 0.9389\n",
      "Epoch 64/90, Loss: 0.1565, Accuracy: 0.9389\n",
      "Epoch 65/90, Loss: 0.1561, Accuracy: 0.9390\n",
      "Epoch 66/90, Loss: 0.1558, Accuracy: 0.9392\n",
      "Epoch 67/90, Loss: 0.1559, Accuracy: 0.9392\n",
      "Epoch 68/90, Loss: 0.1558, Accuracy: 0.9392\n",
      "Epoch 69/90, Loss: 0.1559, Accuracy: 0.9389\n",
      "Epoch 70/90, Loss: 0.1559, Accuracy: 0.9391\n",
      "Epoch 71/90, Loss: 0.1553, Accuracy: 0.9391\n",
      "Epoch 72/90, Loss: 0.1553, Accuracy: 0.9392\n",
      "Epoch 73/90, Loss: 0.1553, Accuracy: 0.9393\n",
      "Epoch 74/90, Loss: 0.1552, Accuracy: 0.9395\n",
      "Epoch 75/90, Loss: 0.1554, Accuracy: 0.9390\n",
      "Epoch 76/90, Loss: 0.1550, Accuracy: 0.9394\n",
      "Epoch 77/90, Loss: 0.1552, Accuracy: 0.9394\n",
      "Epoch 78/90, Loss: 0.1550, Accuracy: 0.9392\n",
      "Epoch 79/90, Loss: 0.1550, Accuracy: 0.9394\n",
      "Epoch 80/90, Loss: 0.1547, Accuracy: 0.9397\n",
      "Epoch 81/90, Loss: 0.1549, Accuracy: 0.9395\n",
      "Epoch 82/90, Loss: 0.1546, Accuracy: 0.9396\n",
      "Epoch 83/90, Loss: 0.1545, Accuracy: 0.9395\n",
      "Epoch 84/90, Loss: 0.1543, Accuracy: 0.9395\n",
      "Epoch 85/90, Loss: 0.1541, Accuracy: 0.9400\n",
      "Epoch 86/90, Loss: 0.1540, Accuracy: 0.9398\n",
      "Epoch 87/90, Loss: 0.1543, Accuracy: 0.9397\n",
      "Epoch 88/90, Loss: 0.1539, Accuracy: 0.9399\n",
      "Epoch 89/90, Loss: 0.1542, Accuracy: 0.9396\n",
      "Epoch 90/90, Loss: 0.1538, Accuracy: 0.9398\n",
      "Test Accuracy: 0.8877\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 90\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for embeddings, labels in train_dataloader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)  \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_dataloader:  \n",
    "        embeddings, labels = embeddings.to(device), labels.to(device) \n",
    "        outputs = model(embeddings) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.1490, Accuracy: 0.9419\n",
      "Epoch 2/100, Loss: 0.1494, Accuracy: 0.9413\n",
      "Epoch 3/100, Loss: 0.1491, Accuracy: 0.9417\n",
      "Epoch 4/100, Loss: 0.1491, Accuracy: 0.9418\n",
      "Epoch 5/100, Loss: 0.1489, Accuracy: 0.9415\n",
      "Epoch 6/100, Loss: 0.1489, Accuracy: 0.9416\n",
      "Epoch 7/100, Loss: 0.1490, Accuracy: 0.9419\n",
      "Epoch 8/100, Loss: 0.1488, Accuracy: 0.9418\n",
      "Epoch 9/100, Loss: 0.1488, Accuracy: 0.9417\n",
      "Epoch 10/100, Loss: 0.1486, Accuracy: 0.9420\n",
      "Epoch 11/100, Loss: 0.1486, Accuracy: 0.9417\n",
      "Epoch 12/100, Loss: 0.1484, Accuracy: 0.9421\n",
      "Epoch 13/100, Loss: 0.1484, Accuracy: 0.9419\n",
      "Epoch 14/100, Loss: 0.1484, Accuracy: 0.9419\n",
      "Epoch 15/100, Loss: 0.1482, Accuracy: 0.9419\n",
      "Epoch 16/100, Loss: 0.1481, Accuracy: 0.9421\n",
      "Epoch 17/100, Loss: 0.1481, Accuracy: 0.9420\n",
      "Epoch 18/100, Loss: 0.1480, Accuracy: 0.9421\n",
      "Epoch 19/100, Loss: 0.1480, Accuracy: 0.9422\n",
      "Epoch 20/100, Loss: 0.1478, Accuracy: 0.9421\n",
      "Epoch 21/100, Loss: 0.1480, Accuracy: 0.9420\n",
      "Epoch 22/100, Loss: 0.1479, Accuracy: 0.9418\n",
      "Epoch 23/100, Loss: 0.1477, Accuracy: 0.9424\n",
      "Epoch 24/100, Loss: 0.1477, Accuracy: 0.9421\n",
      "Epoch 25/100, Loss: 0.1473, Accuracy: 0.9422\n",
      "Epoch 26/100, Loss: 0.1473, Accuracy: 0.9424\n",
      "Epoch 27/100, Loss: 0.1475, Accuracy: 0.9424\n",
      "Epoch 28/100, Loss: 0.1473, Accuracy: 0.9425\n",
      "Epoch 29/100, Loss: 0.1470, Accuracy: 0.9424\n",
      "Epoch 30/100, Loss: 0.1472, Accuracy: 0.9422\n",
      "Epoch 31/100, Loss: 0.1471, Accuracy: 0.9426\n",
      "Epoch 32/100, Loss: 0.1471, Accuracy: 0.9422\n",
      "Epoch 33/100, Loss: 0.1470, Accuracy: 0.9426\n",
      "Epoch 34/100, Loss: 0.1467, Accuracy: 0.9427\n",
      "Epoch 35/100, Loss: 0.1472, Accuracy: 0.9422\n",
      "Epoch 36/100, Loss: 0.1464, Accuracy: 0.9428\n",
      "Epoch 37/100, Loss: 0.1467, Accuracy: 0.9425\n",
      "Epoch 38/100, Loss: 0.1463, Accuracy: 0.9428\n",
      "Epoch 39/100, Loss: 0.1466, Accuracy: 0.9425\n",
      "Epoch 40/100, Loss: 0.1464, Accuracy: 0.9425\n",
      "Epoch 41/100, Loss: 0.1465, Accuracy: 0.9424\n",
      "Epoch 42/100, Loss: 0.1464, Accuracy: 0.9425\n",
      "Epoch 43/100, Loss: 0.1464, Accuracy: 0.9425\n",
      "Epoch 44/100, Loss: 0.1461, Accuracy: 0.9431\n",
      "Epoch 45/100, Loss: 0.1463, Accuracy: 0.9427\n",
      "Epoch 46/100, Loss: 0.1459, Accuracy: 0.9429\n",
      "Epoch 47/100, Loss: 0.1460, Accuracy: 0.9429\n",
      "Epoch 48/100, Loss: 0.1458, Accuracy: 0.9427\n",
      "Epoch 49/100, Loss: 0.1458, Accuracy: 0.9428\n",
      "Epoch 50/100, Loss: 0.1456, Accuracy: 0.9430\n",
      "Epoch 51/100, Loss: 0.1457, Accuracy: 0.9429\n",
      "Epoch 52/100, Loss: 0.1456, Accuracy: 0.9431\n",
      "Epoch 53/100, Loss: 0.1455, Accuracy: 0.9430\n",
      "Epoch 54/100, Loss: 0.1454, Accuracy: 0.9430\n",
      "Epoch 55/100, Loss: 0.1456, Accuracy: 0.9428\n",
      "Epoch 56/100, Loss: 0.1456, Accuracy: 0.9428\n",
      "Epoch 57/100, Loss: 0.1453, Accuracy: 0.9430\n",
      "Epoch 58/100, Loss: 0.1450, Accuracy: 0.9431\n",
      "Epoch 59/100, Loss: 0.1452, Accuracy: 0.9430\n",
      "Epoch 60/100, Loss: 0.1450, Accuracy: 0.9431\n",
      "Epoch 61/100, Loss: 0.1448, Accuracy: 0.9431\n",
      "Epoch 62/100, Loss: 0.1446, Accuracy: 0.9433\n",
      "Epoch 63/100, Loss: 0.1448, Accuracy: 0.9431\n",
      "Epoch 64/100, Loss: 0.1448, Accuracy: 0.9432\n",
      "Epoch 65/100, Loss: 0.1448, Accuracy: 0.9434\n",
      "Epoch 66/100, Loss: 0.1448, Accuracy: 0.9434\n",
      "Epoch 67/100, Loss: 0.1444, Accuracy: 0.9434\n",
      "Epoch 68/100, Loss: 0.1447, Accuracy: 0.9433\n",
      "Epoch 69/100, Loss: 0.1445, Accuracy: 0.9434\n",
      "Epoch 70/100, Loss: 0.1444, Accuracy: 0.9432\n",
      "Epoch 71/100, Loss: 0.1444, Accuracy: 0.9435\n",
      "Epoch 72/100, Loss: 0.1444, Accuracy: 0.9432\n",
      "Epoch 73/100, Loss: 0.1440, Accuracy: 0.9436\n",
      "Epoch 74/100, Loss: 0.1440, Accuracy: 0.9435\n",
      "Epoch 75/100, Loss: 0.1441, Accuracy: 0.9434\n",
      "Epoch 76/100, Loss: 0.1439, Accuracy: 0.9435\n",
      "Epoch 77/100, Loss: 0.1438, Accuracy: 0.9436\n",
      "Epoch 78/100, Loss: 0.1436, Accuracy: 0.9438\n",
      "Epoch 79/100, Loss: 0.1437, Accuracy: 0.9436\n",
      "Epoch 80/100, Loss: 0.1436, Accuracy: 0.9436\n",
      "Epoch 81/100, Loss: 0.1436, Accuracy: 0.9437\n",
      "Epoch 82/100, Loss: 0.1437, Accuracy: 0.9437\n",
      "Epoch 83/100, Loss: 0.1436, Accuracy: 0.9439\n",
      "Epoch 84/100, Loss: 0.1434, Accuracy: 0.9437\n",
      "Epoch 85/100, Loss: 0.1432, Accuracy: 0.9438\n",
      "Epoch 86/100, Loss: 0.1431, Accuracy: 0.9440\n",
      "Epoch 87/100, Loss: 0.1430, Accuracy: 0.9437\n",
      "Epoch 88/100, Loss: 0.1433, Accuracy: 0.9439\n",
      "Epoch 89/100, Loss: 0.1431, Accuracy: 0.9436\n",
      "Epoch 90/100, Loss: 0.1431, Accuracy: 0.9437\n",
      "Epoch 91/100, Loss: 0.1432, Accuracy: 0.9437\n",
      "Epoch 92/100, Loss: 0.1428, Accuracy: 0.9441\n",
      "Epoch 93/100, Loss: 0.1429, Accuracy: 0.9437\n",
      "Epoch 94/100, Loss: 0.1431, Accuracy: 0.9438\n",
      "Epoch 95/100, Loss: 0.1426, Accuracy: 0.9442\n",
      "Epoch 96/100, Loss: 0.1427, Accuracy: 0.9439\n",
      "Epoch 97/100, Loss: 0.1426, Accuracy: 0.9439\n",
      "Epoch 98/100, Loss: 0.1429, Accuracy: 0.9438\n",
      "Epoch 99/100, Loss: 0.1427, Accuracy: 0.9438\n",
      "Epoch 100/100, Loss: 0.1424, Accuracy: 0.9443\n",
      "Test Accuracy: 0.8917\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for embeddings, labels in train_dataloader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)  \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, labels in test_dataloader:  \n",
    "        embeddings, labels = embeddings.to(device), labels.to(device) \n",
    "        outputs = model(embeddings) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Training Loss', color='royalblue')\n",
    "plt.plot(range(1, epochs+1), val_losses, label='Validation Loss', color='tomato')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        X_batch, y_batch = batch\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        labels = y_batch.cpu().numpy()\n",
    "\n",
    "        predictions.extend(preds)\n",
    "        true_labels.extend(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8953533860731983\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90     61349\n",
      "           1       0.86      0.92      0.89     61349\n",
      "           2       0.94      0.86      0.90     61350\n",
      "\n",
      "    accuracy                           0.90    184048\n",
      "   macro avg       0.90      0.90      0.90    184048\n",
      "weighted avg       0.90      0.90      0.90    184048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Classification Report\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Test Accuracy: {accuracy:}\")\n",
    "print(\"Classification Report:\\n\", classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1,2], yticklabels=[0,1,2])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "torch.save(model.state_dict(), \"cbf_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT_Classifier(\n",
       "  (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model again (same architecture)\n",
    "model = BERT_Classifier(input_size, num_classes)\n",
    "\n",
    "# Load the saved weights\n",
    "model.load_state_dict(torch.load(\"cbf_model.pth\"))\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from C:/Users/mochi/OneDrive/Documents/MMU/Bachelors in Computer Science/FYP/code/cleaned_merged.csv. Shape: (393560, 2)\n",
      "Found 256027 unique users.\n",
      "Found 67553 unique items.\n",
      "User encoder saved to user_encoder.pkl\n",
      "Item encoder saved to item_encoder.pkl\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "67553\n",
      "['0006641040', '141278509X', '2734888454', '2841233731', '7800648702', '9376674501', 'B00002N8SM', 'B00002NCJC', 'B00002Z754', 'B00004CXX9']\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "# import numpy as np # If the pkl might contain numpy arrays\n",
    "\n",
    "# file_path = 'item_encoder.pkl'\n",
    "# # file_path = 'user_encoder.pkl'\n",
    "\n",
    "# with open(file_path, 'rb') as f:\n",
    "#     loaded_data = pickle.load(f)\n",
    "    \n",
    "# # Now inspect the loaded_data variable\n",
    "# print(type(loaded_data))\n",
    "# print(len(loaded_data)) # If it's a list/dict/array\n",
    "# print(loaded_data[:10]) # Print the first 10 elements if it's a list/array\n",
    "# # Or explore keys if it's a dictionary\n",
    "# # print(list(loaded_data.keys())[:10]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
